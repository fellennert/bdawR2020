
@misc{bache2014,
  title = {Magrittr: {{A Forward}}-{{Pipe Operator}} for {{R}}},
  author = {Bache, Stephan Milton and Wickham, Hadley},
  year = {2014}
}

@article{brady2019a,
  title = {The {{Challenge}} of {{Big Data}} and {{Data Science}}},
  author = {Brady, Henry E.},
  year = {2019},
  month = may,
  volume = {22},
  pages = {297--323},
  issn = {1094-2939, 1545-1577},
  doi = {10.1146/annurev-polisci-090216-023229},
  abstract = {Big data and data science are transforming the world in ways that spawn new concerns for social scientists, such as the impacts of the internet on citizens and the media, the repercussions of smart cities, the possibilities of cyberwarfare and cyber-terrorism, the implications of precision medicine, and the consequences of artificial intelligence and automation. Along with these changes in society, powerful new data science methods support research using administrative, internet, textual, and sensor-audio-video data. Burgeoning data and innovative methods facilitate answering previously hard-totackle questions about society by offering new ways to form concepts from data, to do descriptive inference, to make causal inferences, and to generate predictions. They also pose challenges as social scientists must grasp the meaning of concepts and predictions generated by convoluted algorithms, weigh the relative value of prediction versus causal inference, and cope with ethical challenges as their methods, such as algorithms for mobilizing voters or determining bail, are adopted by policy makers.},
  file = {/Users/felixlennert/Zotero/storage/H4Z3XEJ9/Brady - 2019 - The Challenge of Big Data and Data Science.pdf},
  journal = {Annual Review of Political Science},
  language = {en},
  number = {1}
}

@techreport{bryan2017,
  title = {Excuse Me, Do You Have a Moment to Talk about Version Control?},
  author = {Bryan, Jennifer},
  year = {2017},
  month = aug,
  institution = {{PeerJ Preprints}},
  doi = {10.7287/peerj.preprints.3159v2},
  abstract = {Data analysis, statistical research, and teaching statistics have at least one thing in common: these activities all produce many files! There are data files, source code, figures, tables, prepared reports, and much more. Most of these files evolve over the course of a project and often need to be shared with others, for reading or edits, as a project unfolds. Without explicit and structured management, project organization can easily descend into chaos, taking time away from the primary work and reducing the quality of the final product. This unhappy result can be avoided by repurposing tools and workflows from the software development world, namely, distributed version control. This article describes the use of the version control system Git and and the hosting site GitHub for statistical and data scientific workflows. Special attention is given to projects that use the statistical language R and, optionally, R Markdown documents. Supplementary materials include an annotated set of links to step-by-step tutorials, real world examples, and other useful learning resources.},
  file = {/Users/felixlennert/Zotero/storage/Z2WYXE8X/Bryan - 2017 - Excuse me, do you have a moment to talk about vers.pdf},
  language = {en},
  type = {Preprint}
}

@book{burns2011,
  title = {The {{R}} Inferno},
  author = {Burns, Patrick},
  year = {2011},
  isbn = {978-1-4710-4652-0},
  language = {English}
}

@book{cotton2013,
  title = {Learning {{R}}},
  author = {Cotton, Richard},
  year = {2013},
  edition = {First Edition},
  publisher = {{O'Reilly}},
  address = {{Beijing ; Sebastopol, CA}},
  isbn = {978-1-4493-5710-8},
  keywords = {Data processing,R (Computer program language),Statistics},
  lccn = {QA276.45.R3 C68 2013}
}

@inproceedings{demauro2015,
  title = {What Is Big Data? {{A}} Consensual Definition and a Review of Key Research Topics},
  shorttitle = {What Is Big Data?},
  booktitle = {{{INTERNATIONAL CONFERENCE ON INTEGRATED INFORMATION}} ({{IC}}-{{ININFO}} 2014): {{Proceedings}} of the 4th {{International Conference}} on {{Integrated Information}}},
  author = {De Mauro, Andrea and Greco, Marco and Grimaldi, Michele},
  year = {2015},
  pages = {97--104},
  address = {{Madrid, Spain}},
  doi = {10.1063/1.4907823},
  abstract = {Although Big Data is a trending buzzword in both academia and the industry, its meaning is still shrouded by much conceptual vagueness. The term is used to describe a wide range of concepts: from the technological ability to store, aggregate, and process data, to the cultural shift that is pervasively invading business and society, both drowning in information overload. The lack of a formal definition has led research to evolve into multiple and inconsistent paths. Furthermore, the existing ambiguity among researchers and practitioners undermines an efficient development of the subject. In this paper we have reviewed the existing literature on Big Data and analyzed its previous definitions in order to pursue two results: first, to provide a summary of the key research areas related to the phenomenon, identifying emerging trends and suggesting opportunities for future development; second, to provide a consensual definition for Big Data, by synthesizing common themes of existing works and patterns in previous definitions.},
  file = {/Users/felixlennert/Zotero/storage/8XN89QQ9/De Mauro et al. - 2015 - What is big data A consensual definition and a re.pdf},
  language = {en}
}

@article{garcia2019a,
  title = {Collective {{Emotions}} and {{Social Resilience}} in the {{Digital Traces After}} a {{Terrorist Attack}}},
  author = {Garcia, David and Rim{\'e}, Bernard},
  year = {2019},
  volume = {30},
  pages = {617--628},
  abstract = {After collective traumas such as natural disasters and terrorist attacks, members of concerned communities experience intense emotions and talk profusely about them. Although these exchanges resemble simple emotional venting, Durkheim's theory of collective effervescence postulates that these collective emotions lead to higher levels of solidarity in the affected community. We present the first large-scale test of this theory through the analysis of digital traces of 62,114 Twitter users after the Paris terrorist attacks of November 2015. We found a collective negative emotional response followed by a marked long-term increase in the use of lexical indicators related to solidarity. Expressions of social processes, prosocial behavior, and positive affect were higher in the months after the attacks for the individuals who participated to a higher degree in the collective emotion. Our findings support the conclusion that collective emotions after a disaster are associated with higher solidarity, revealing the social resilience of a community.},
  file = {/Users/felixlennert/Zotero/storage/ZR7KPB8S/Garcia and Rimé - Collective Emotions and Social Resilience in the D.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {4}
}

@book{grolemund2014,
  title = {Hands-on Programming with {{R}}},
  author = {Grolemund, Garrett},
  year = {2014},
  edition = {First edition},
  publisher = {{O'Reilly}},
  address = {{Sebastopol, CA}},
  isbn = {978-1-4493-5901-0},
  keywords = {Data processing,Handbooks; manuals; etc,Mathematical statistics,Programmeertalen,R (Computer program language),Statistiek},
  lccn = {QA276.45.R3 G76 2014}
}

@misc{hester2018,
  title = {Readr: {{Read Rectangular Text Data}}},
  author = {Hester, Jim and Wickham, Hadley and Fran{\c c}ois, Romain and Jyl{\"a}nki, Jukka and J{\o}rgensen, Mikkel},
  year = {2018}
}

@misc{hester2020,
  title = {Vroom: {{Read}} and {{Write Rectangular Text Data Quickly}}},
  author = {Hester, Jim and Wickham, Hadley and Jyl{\"a}nki, Jukka and J{\o}rgensen, Mikkel},
  year = {2020}
}

@article{lazer2009,
  title = {Life in the Network: The Coming Age of Computational Social Science},
  shorttitle = {{{SOCIAL SCIENCE}}},
  author = {Lazer, D. and Pentland, A. and Adamic, L. and Aral, S. and Barabasi, A.-L. and Brewer, D. and Christakis, N. and Contractor, N. and Fowler, J. and Gutmann, M. and Jebara, T. and King, G. and Macy, M. and Roy, D. and Van Alstyne, M.},
  year = {2009},
  month = feb,
  volume = {323},
  pages = {721--723},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1167742},
  file = {/Users/felixlennert/Zotero/storage/855397D4/Lazer et al. - 2009 - SOCIAL SCIENCE Computational Social Science.pdf},
  journal = {Science},
  language = {en},
  number = {5915}
}

@article{lazer2017a,
  title = {Data Ex {{Machina}}: {{Introduction}} to {{Big Data}}},
  shorttitle = {Data Ex {{Machina}}},
  author = {Lazer, David and Radford, Jason},
  year = {2017},
  month = jul,
  volume = {43},
  pages = {19--39},
  issn = {0360-0572, 1545-2115},
  doi = {10.1146/annurev-soc-060116-053457},
  abstract = {Social life increasingly occurs in digital environments and continues to be mediated by digital systems. Big data represents the data being generated by the digitization of social life, which we break down into three domains: digital life, digital traces, and digitalized life. We argue that there is enormous potential in using big data to study a variety of phenomena that remain difficult to observe. However, there are some recurring vulnerabilities that should be addressed. We also outline the role institutions must play in clarifying the ethical rules of the road. Finally, we conclude by pointing to a number of nascent but important trends in the use of big data.},
  file = {/Users/felixlennert/Zotero/storage/MXQ9XZAI/Lazer and Radford - 2017 - Data ex Machina Introduction to Big Data.pdf},
  journal = {Annual Review of Sociology},
  language = {en},
  number = {1}
}

@techreport{mcnamara2017,
  title = {Wrangling Categorical Data in {{R}}},
  author = {McNamara, Amelia and Horton, Nicholas J},
  year = {2017},
  month = aug,
  institution = {{PeerJ Preprints}},
  doi = {10.7287/peerj.preprints.3163v2},
  abstract = {Data wrangling is a critical foundation of data science, and wrangling of categorical data is an important component of this process. However, categorical data can introduce unique issues in data wrangling, particularly in real-world settings with collaborators and periodically-updated dynamic data. This paper discusses common problems arising from categorical variable transformations in R, demonstrates the use of factors, and suggests approaches to address data wrangling challenges. For each problem, we present at least two strategies for management, one in base R and the other from the `tidyverse.' We consider several motivating examples, suggest defensive coding strategies, and outline principles for data wrangling to help ensure data quality and sound analysis.},
  file = {/Users/felixlennert/Zotero/storage/JR4XMM4H/McNamara and Horton - 2017 - Wrangling categorical data in R.pdf},
  language = {en},
  type = {Preprint}
}

@misc{muller2020,
  title = {Tibble: {{Simple Data Frames}}},
  author = {M{\"u}ller, Kirill and Wickham, Hadley and Fran{\c c}ois, Romain},
  year = {2020}
}

@article{pfeffer2018,
  title = {Tampering with {{Twitter}}'s {{Sample API}}},
  author = {Pfeffer, J{\"u}rgen and Mayer, Katja and Morstatter, Fred},
  year = {2018},
  month = dec,
  volume = {7},
  pages = {50},
  issn = {2193-1127},
  doi = {10.1140/epjds/s13688-018-0178-0},
  abstract = {Social media data is widely analyzed in computational social science. Twitter, one of the largest social media platforms, is used for research, journalism, business, and government to analyze human behavior at scale. Twitter offers data via three different Application Programming Interfaces (APIs). One of which, Twitter's Sample API, provides a freely available 1\% and a costly 10\% sample of all Tweets. These data are supposedly random samples of all platform activity. However, we demonstrate that, due to the nature of Twitter's sampling mechanism, it is possible to deliberately influence these samples, the extent and content of any topic, and consequently to manipulate the analyses of researchers, journalists, as well as market and political analysts trusting these data sources. Our analysis also reveals that technical artifacts can accidentally skew Twitter's samples. Samples should therefore not be regarded as random. Our findings illustrate the critical limitations and general issues of big data sampling, especially in the context of proprietary data and undisclosed details about data handling.},
  file = {/Users/felixlennert/Zotero/storage/JVGRL2WX/Pfeffer et al. - 2018 - Tampering with Twitter’s Sample API.pdf},
  journal = {EPJ Data Science},
  language = {en},
  number = {1}
}

@article{ruths2014b,
  title = {Social Media for Large Studies of Behavior},
  author = {Ruths, Derek and Pfeffer, J{\"u}rgen},
  year = {2014},
  month = nov,
  volume = {346},
  pages = {1063--1064},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.346.6213.1063},
  file = {/Users/felixlennert/Zotero/storage/P69IANIZ/Ruths and Pfeffer - 2014 - Social media for large studies of behavior.pdf},
  journal = {Science},
  language = {en},
  number = {6213}
}

@book{salganik2017,
  title = {Bit by Bit: Social Research in the Digital Age},
  shorttitle = {Bit by Bit},
  author = {Salganik, Matthew J.},
  year = {2018},
  publisher = {{Princeton University Press}},
  address = {{Princeton}},
  abstract = {An innovative and accessible guide to doing social research in the digital age. In just the past several years, we have witnessed the birth and rapid spread of social media, mobile phones, and numerous other digital marvels. In addition to changing how we live, these tools enable us to collect and process data about human behavior on a scale never before imaginable, offering entirely new approaches to core questions about social behavior. Bit by Bit is the key to unlocking these powerful methods-a landmark book that will fundamentally change how the next generation of social scientists and data scientists explores the world around us. Bit by Bit is the essential guide to mastering the key principles of doing social research in this fast-evolving digital age. In this comprehensive yet accessible book, Matthew Salganik explains how the digital revolution is transforming how social scientists observe behavior, ask questions, run experiments, and engage in mass collaborations. He provides a wealth of real-world examples throughout, and also lays out a principles-based approach to handling ethical challenges in the era of social media. Bit by Bit is an invaluable resource for social scientists who want to harness the research potential of big data and a must-read for data scientists interested in applying the lessons of social science to tomorrow's technologies},
  isbn = {978-0-691-15864-8},
  keywords = {Ethics,Information technology,Research Methodology,Social media,Social sciences,Sociology,Statistical methods},
  lccn = {H62 .S3189 2018}
}

@article{stephens-davidowitz2014a,
  title = {The Cost of Racial Animus on a Black Candidate: {{Evidence}} Using {{Google}} Search Data},
  shorttitle = {The Cost of Racial Animus on a Black Candidate},
  author = {{Stephens-Davidowitz}, Seth},
  year = {2014},
  month = oct,
  volume = {118},
  pages = {26--40},
  issn = {00472727},
  doi = {10.1016/j.jpubeco.2014.04.010},
  abstract = {How can we know how much racial animus costs a black presidential candidate, if many people lie to surveys? I suggest a new proxy for an area's racial animus from a non-survey source: the percent of Google search queries that include racially charged language. I compare the proxy to Barack Obama's vote shares, controlling for the vote share of the previous Democratic presidential candidate, John Kerry. An area's racially charged search rate is a robust negative predictor of Obama's vote share. Continuing racial animus in the United States appears to have cost Obama roughly four percentage points of the national popular vote in both 2008 and 2012. The estimates using Google search data are 1.5 to 3 times larger than survey-based estimates.},
  file = {/Users/felixlennert/Zotero/storage/5ZG37K49/Stephens-Davidowitz - 2014 - The cost of racial animus on a black candidate Ev.pdf},
  journal = {Journal of Public Economics},
  language = {en}
}

@article{watts2004,
  title = {The ``{{New}}'' {{Science}} of {{Networks}}},
  author = {Watts, Duncan J.},
  year = {2004},
  month = aug,
  volume = {30},
  pages = {243--270},
  issn = {0360-0572, 1545-2115},
  doi = {10.1146/annurev.soc.30.020404.104342},
  file = {/Users/felixlennert/Zotero/storage/IVHHSKRE/Watts - 2004 - The “New” Science of Networks.pdf},
  journal = {Annual Review of Sociology},
  language = {en},
  number = {1}
}

@article{wickham2011,
  title = {The {{Split}}-{{Apply}}-{{Combine Strategy}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  year = {2011},
  volume = {40},
  issn = {1548-7660},
  doi = {10.18637/jss.v040.i01},
  file = {/Users/felixlennert/Zotero/storage/45FX8JSE/Wickham - 2011 - The Split-Apply-Combine Strategy for Data Analysis.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{wickham2014,
  title = {Tidy {{Data}}},
  author = {Wickham, Hadley},
  year = {2014},
  volume = {59},
  issn = {1548-7660},
  doi = {10.18637/jss.v059.i10},
  file = {/Users/felixlennert/Zotero/storage/DDECUM5H/Wickham - 2014 - Tidy Data.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {10}
}

@book{wickham2016a,
  title = {R for Data Science: Import, Tidy, Transform, Visualize, and Model Data},
  shorttitle = {R for Data Science},
  author = {Wickham, Hadley and Grolemund, Garrett},
  year = {2016},
  edition = {First edition},
  publisher = {{O'Reilly}},
  address = {{Sebastopol, CA}},
  abstract = {"This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience"--},
  isbn = {978-1-4919-1039-9 978-1-4919-1036-8},
  keywords = {Big data,Computer programs,Data mining,Databases,Electronic data processing,Information visualization,R (Computer program language),Statistics},
  lccn = {QA276.45.R3 W53 2016}
}

@article{wickham2019c,
  title = {Welcome to the {{Tidyverse}}},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas and Miller, Evan and Bache, Stephan and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  month = nov,
  volume = {4},
  pages = {1686},
  issn = {2475-9066},
  doi = {10.21105/joss.01686},
  file = {/Users/felixlennert/Zotero/storage/4KQWYGER/Wickham et al. - 2019 - Welcome to the Tidyverse.pdf},
  journal = {Journal of Open Source Software},
  number = {43}
}

@misc{wickham2019d,
  title = {Feather: {{R Bindings}} to the {{Feather}} '{{API}}'},
  author = {Wickham, Hadley},
  year = {2019}
}

@misc{wickham2019e,
  title = {Readxl: {{Read Excel Files}}},
  author = {Wickham, Hadley and Bryan, Jennifer and Valery, Komarov and Leitienne, Christophe and Colbert, Bob and Hoerl, David and Miller, Evan},
  year = {2019}
}

@misc{wickham2020,
  title = {Dplyr: {{A Grammar}} of {{Data Manipulation}}},
  author = {Wickham, Hadley},
  year = {2020}
}

@misc{wickham2020a,
  title = {Tidyr: {{Tidy Messy Data}}},
  author = {Wickham, Hadley},
  year = {2020}
}

@misc{wickham2020b,
  title = {Haven: {{Import}} and {{Export}} '{{SPSS}}', '{{Stata}}' and '{{SAS}}' {{Files}}},
  author = {Wickham, Hadley and Miller, Evan},
  year = {2020}
}

@book{xie2018,
  title = {R {{Markdown}}: The Definitive Guide},
  shorttitle = {R {{Markdown}}},
  author = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
  year = {2018},
  publisher = {{Taylor \& Francis, CRC Press}},
  address = {{Boca Raton}},
  isbn = {978-1-138-35933-8},
  keywords = {Computer programs,Markdown (Document markup language),R (Computer program language),Web site development},
  lccn = {TK5105.8885.M39 X393 2018}
}


